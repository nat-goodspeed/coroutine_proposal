\abschnitt{Motivation}

This proposal refers to \boostcoroutine as reference implementation - providing
a test suite and examples (some are described in this section).\\
\newline
In order to support a broad range of execution control behaviour the coroutine
types of \scoro and \acoro can be used to \escrecloops, to \escreccomps and for
\coopmultitasking helping to solve problems in a much simpler and more elegant
way than with only a single flow of control.

\subsubsection*{event-driven model}
The event-driven model is a programming paradigm where the flow of a program is
determined by events. The events are generated by multiple independent sources
and an event-dispatcher, waiting on all external sources, triggers callback
functions (event-handlers) whenever one of those events is detected (event-loop).
The application is divided into event selection (detection) and event handling.
\imgc{event_model.pdf}

The resulting applications are highly scalable, flexible, have high
responsiveness and the components are loosely coupled. This makes the event-driven
model suitable for user interface applications, rule-based productions systems
or applications dealing with asynchronous I/O (for instance network servers).


\subsubsection*{event-based asynchronous paradigm}
A classic synchronous console program issues an I/O request (e.g. for user
input or filesystem data) and blocks until the request is complete.
\newline
In contrast, an asynchronous I/O function initiates the physical operation but
immediately returns to its caller, even though the operation is not yet
complete. A program written to leverage this functionality does not block: it
can proceed with other work (including other I/O requests in parallel) while
the original operation is still pending. When the operation completes, the
program is notified. Because asynchronous applications spend less overall time
waiting for operations, they can outperform synchronous programs.
\newline
Events are one of the paradigms for asynchronous execution, but
not all asynchronous systems use events.
Although asynchronous programming can be done using threads, they come with
their own costs:

\begin{itemize}
    \item hard to program (traps for the unwary)
    \item memory requirements are high
    \item large overhead with creation and maintenance of thread state
    \item expensive context switching between threads
\end{itemize}

The event-based asynchronous model avoids those issues:

\begin{itemize}
    \item simpler because of the single stream of instructions
    \item much less expensive context switches
\end{itemize}

The downside of this paradigm consists in a sub-optimal program
structure. A event-driven program is required to split its code into
multiple small callback functions, i.e. the code is organized in a sequence of
small steps that execute intermittently. An algorithm that would usually be
expressed as a hierarchy of functions and loops must be transformed into
callbacks. The complete state has to be stored into a data structure while the
control flow returns to the event-loop.\\
As a consequence, event-driven applications are often tedious and confusing to
write. Each callback introduces a new scope, error callback etc. The
sequential nature of the algorithm is split into multiple callstacks,
making the application hard to debug. Exception handlers are restricted to
local handlers: it is impossible to wrap a sequence of events into a single
try-catch block.
The use of local variables, while/for loops, recursions etc. together with the
event-loop is not possible. The code becomes less expressive.\\
\newline
In the past, code using asio's \asyncops was convoluted by
callback functions.
\cppf{oldasio.cpp}

In this example, a simple echo server, the logic is split into three member
functions - local state (such as data buffer) is moved to member variables.\\
\newline
\boostasio provides with its new \asyncres feature a new
framework combining event-driven model and coroutines, hiding the complexity
of event-driven programming and permitting the style of classic sequential code.
The application is not required to pass callback functions to asynchronous
operations and local state is kept as local variables. Therefore the code
is much easier to read and understand.
Proposal 'N3964: Library Foundations for Asynchronous Operations'\cite{n3964}
describes the usage of coroutines in the context of asynchronous operations.\\
\yieldcontext internally uses \boostcoroutine:
\cppf{coroasio.cpp}

In contrast to the previous example this one gives the impression of sequential
code and local data while using asynchronous operations \asyncread and
\asyncwrite. The algorithm is implemented in one function and error handling is
done by one try-catch block.

\subsubsection*{recursive SAX parsing}
To someone who knows SAX, the phrase "recursive SAX parsing" might sound
nonsensical. You get callbacks from SAX; you have to manage the element stack
yourself. If you want recursive XML processing, you must first read the entire
DOM into memory, then walk the tree.

But coroutines let you invert the flow of control so you can ask for SAX
events. Once you can do that, you can process them recursively.

\cppf{sax_parsing.cpp}

This problem does not map at all well to communicating between independent
threads. It makes no sense for either side to proceed independently of the
other. You want them to pass control back and forth.

The solution involves a small polymorphic class event hierarchy, to which
we're passing references. The actual instances are temporaries on the
coroutine's stack; the coroutine passes each reference in turn to the main
logic. Copying them as base-class values would slice them.

If we were trying to let the SAX parser proceed independently of the consuming
logic, one could imagine allocating event-subclass instances on the heap,
passing them along on a thread-safe queue of pointers. But that doesn't work
either, because these event classes bind references passed by the SAX parser.
The moment the parser moves on, those references become invalid.

Instead of binding a \cpp{TagType&} reference, we could store a copy of
the \cpp{TagType} in \cpp{CloseEvent}. But that doesn't solve the whole
problem. For attributes, we get an \cpp{AttributeIterator&}; for text we get
a \cpp{CharIterator&}. Storing a copy of those iterators is pointless: once
the parser moves on, those iterators are invalidated. You must process the
attribute iterator (or character iterator) during the SAX callback for that
event.

Naturally we could retrieve and store a copy of every attribute and its value;
we could store a copy of every chunk of text. That would effectively be all
the text in the document -- a heavy price to pay, if the reason we're using
SAX is concern about fitting the entire DOM into memory.

There's yet another advantage to using coroutines. This SAX parser throws an
exception when parsing fails. With a coroutine implementation, you need only
wrap the calling code in try/catch.

With communicating threads, you would have to arrange to catch the exception
and pass along the exception pointer on the same queue you're using to deliver
the other events. You would then have to rethrow the exception to unwind the
recursive document processing.

The coroutine solution maps very naturally to the problem space.

\subsubsection*{'same fringe' problem}
The advantages of stackful coroutines can be seen particularly clearly with
the use of a recursive function, such as traversal of trees.\\
If traversing two different trees in the same deterministic order produces the
same list of leaf nodes, then both trees have the same fringe even if the tree
structure is different.\\
\newline
The same fringe problem could be solved using coroutines by iterating over the
leaf nodes and comparing this sequence via \cpp{std::equal()}. The range of data
values is generated by function \cpp{traverse()} which recursively traverses the
tree and passes each node's data value to its \pushcoro.\\
\pushcoro suspends the recursive computation and transfers the data value to
the main execution context.\\
\pullcoroiterator, created from \pullcoro, steps over those data values and
delivers them to \cpp{std::equal()} for comparison. Each increment of \pullcoroiterator
resumes \cpp{traverse()}. Upon return from \cpp{iterator::operator++()}, either
a new data value is available, or tree traversal is finished (iterator is
invalidated).
\cppf{same_fringe.cpp}

\subsubsection*{\csharp \await}
\csharp contains the two keywords \async and \await. \async introduces a
control flow that involves awaiting asynchronous operations. The compiler
reorganizes the code into a continuation-passing style. \await wraps the rest
of the function after calling \await into a continuation if the asynchronous
operation has not yet completed.\\
The project \awaitemu uses \boostcoroutine for a proof-of-concept
demonstrating the implementation of a full emulation of \csharp \await as a
library extension. Because of stackful coroutines \await is \textbf{not limited}
by "one level" as in \csharp.\\
Evgeny Panasyuk describes the advantages of \boostcoroutine over \await at
\channelnine.
\cppf{await.cpp}
